NAME: Scott Hetrick
EMAIL: scotthetrick2@yahoo.com
ID: 404491101
SLIPDAYS: 5

## Files
* README - this file.
* Makefile - contains 'build', 'dist', 'clean', 'tests' & 'graphs' as specificied in the spec.
* imports.c - helper functions & imports, placed in a separate file for no particular reason.
* SortedList.h - provided header file for SortedList.
* SortedList.c - implementation for SortedList.
* lab2_list.c - implementation for lab2_list modifying a shared linked list (with additional --list option).
* lab2b_list.gp - data file used to generate graphs for lab2_list.
* lab2b_list.csv - generated data file for lab2_list from 'make tests'
* lab2b_1.png - graph of throughput for mutex and spinlock.
* lab2b_2.png - graph of wait-for-lock and average time per operation vs threads
* lab2b_3.png - graph of unprotected/protected threads and iterations that run without failure
* lab2b_4.png - graph of throughput vs threads (sync=m)
* lab2b_5.png - graph of throughput vs threads (sync=s)
* profile.out - diagnostic information gotten from 'make profile'

##Questions
###2.3.1 - Cycles in the basic list implementation:
Where do you believe most of the cycles are spent in the 1 and 2-thread list tests ?
* Most of the cycles are spent carrying out list operations. In 2-thread tests there is some time spent waiting on locks, but for the most part time is primarily spent on list operations.
Why do you believe these to be the most expensive parts of the code?
* The most expensive operations are the overhead associated with locks and the four list operations.
Where do you believe most of the time/cycles are being spent in the high-thread spin-lock tests?
* With high contention for resources, spinlocks will spend most of their time spinning.
Where do you believe most of the time/cycles are being spent in the high-thread mutex tests?
* The mutex tests should be spending most of their time on list operations, since mutexes do not take up unnecessary CPU time.

###2.3.2 - Execution Profiling:
Where (what lines of code) are consuming most of the cycles when the spin-lock version of the list exerciser is run with a large number of threads?
* Most of the execution time is spent spinning to access the lock for critical sections.
Why does this operation become so expensive with large numbers of threads?
* The more threads there are, the higher the contention for shared resources is, resulting in a greater bottleneck at critical sections.

###2.3.3 - Mutex Wait Time:
Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
* Average wait-for-mutex time increases greatly with increasing numbers of threads because there are more threads competing for the same locks.
Why does the average lock-wait time rise so dramatically with the number of contending threads?
* Average lock-wait time rises so dramatically because only one thread can have the lock at a time, so the greater the number of threads, the longer each thread will have to wait to acquire the lock.
Why does the completion time per operation rise (less dramatically) with the number of contending threads?
* Completion time is amortized over all parts of an operation, so it increases more slowly because it's more of an average.
How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?
* Wait time does not take into account all of the contention of increasing threads, causing greater bottlenecks despite having individual threads complete more quickly.

###2.3.4 - Performance of Partitioned Lists
Explain the change in performance of the synchronized methods as a function of the number of lists.
* Performance increases as the number of sublists increases. This is a result of subdividing the list into buckets that can be modified in parallel, allowing for greater granularity with locks.
Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
* There is a point of limited returns, but the throughput should theoretically keep increasing until all operations that can be completely parallelized are executed in parallel.
It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput of a single list with fewer (1/N) threads. Does this appear to be true in the above curves? If not, explain why not.
* No. A factor is the smaller length of sublists, which causes list operations to execute more quickly. This makes critical sections consume less time.